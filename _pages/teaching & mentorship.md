---
layout: archive
title: 
permalink: /teaching_mentorship/
author_profile: true
redirect_from:
  - /resume
---

{% include base_path %}

Teaching
======

* **Mechanisms & Robotics (ME G511)** : August 2022 - December 2022 \
    Birla Institute of Technology and Science, Pilani \
    Participated in the evaluation and development of assignments based on robot kinematics, dynamics and controls in
    collaboration with a [Prof. Bijay Kumar Rout](https://www.bits-pilani.ac.in/pilani/teaching/?faculty=bijay-k-routphd).

---

Mentorship
======

Worked with 5 undergraduate students and a post doc as part of their internship/course project, related to robot skill development for the robotic manipulator. A few of the projects are :\

* **Human Modelling from RGBD Sensors for Robotic Applications** : May 2024 - July 2024
In assistive technology, modeling the human(s) to be assisted in the robot's world model is crucial for smooth task execution. This includes recognizing the human's identity, 3D location, posture, and commands. This project explores human modeling using RGB-D sensors, integrating object detection models like YOLO for human detection and tracking, and face recognition models like SFace for identifying individuals. We propose a method to simultaneously detect, recognize, and track humans in dynamic environments using a ROS-based pipeline. This pipeline labels tracked individuals, calculates their 3D location, and localizes the speaking person with a ReSpeaker Mic Array for task execution based on voice commands. [Report](https://drive.google.com/file/d/1cOxQ_YaNejphPoZd9czq340CaRp3hRph/view?usp=sharing)

* **Automatic Extraction of Semantic Information from Visual+3D Data for Intelligent** : May 2024 - July 2024
This project focuses on developing a system for the automatic extraction of semantic information from visual and 3D data, specifically designed to enhance the functionality of intelligent robots. The system is tailored to improve robotic performance in low-light environments, which is critical for applications such as defense, surveillance, and exploration. By leveraging ground-based point cloud data, the project ensures high reliability and accuracy in real-world scenarios. Key objectives include segmenting different object classes from point cloud data and benchmarking the effectiveness of 3D segmentation models. [Report](https://drive.google.com/file/d/1RjMg3org7P2hqeDd1RstbnUpBVgWAEyp/view?usp=sharing)

* **Static and Dynamic Gesture Instructed Robot Task Execution**
Description to be added.